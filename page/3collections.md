---
layout: page
title: Collections
permalink: /collection/
icon: bookmark
type: page
---

* content
{:toc}
## NLP预训练模型

- [NNLM论文《A Neural Probabilistic Language Model》](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)
- [Word2Vec论文《Distributed Representations of Words and Phrases and their Compositionality》](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
- [Glove论文《GloVe: Global Vectors for Word Representation》](https://nlp.stanford.edu/pubs/glove.pdf)
- [Attention论文《Attention is all you need》](https://arxiv.org/pdf/1706.03762.pdf)
- [张俊林《深度学习中的注意力模型（2017版）》](https://zhuanlan.zhihu.com/p/37601161)
- [哈佛大学 NLP 研究组介绍 Transformer《The Annotated Transformer》](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
- [EMLO论文《Deep contextualized word representations》](https://arxiv.org/pdf/1802.05365.pdf)
- [GPT论文《GPT: Improving Language Understanding by Generative Pre-Training》](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf)
- [BERT论文《BERT:Pre-training of Deep Bidirectional Transformers for Language Understanding》](https://arxiv.org/pdf/1810.04805.pdf)
- [微软MT-DNN论文《Multi-Task Deep Neural Networks for Natural Language Understanding》](https://arxiv.org/pdf/1901.11504.pdf)
- [GPT2论文《Language Models are Unsupervised Multitask Learners》](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- 微信《由 Attention 看 OpenAI 的网红 GPT》
- [张俊林知乎专栏《效果惊人的GPT 2.0模型：它告诉了我们什么》](https://zhuanlan.zhihu.com/p/56865533)
- [张俊林知乎专栏《从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史》](https://zhuanlan.zhihu.com/p/49271699)
- [张俊林知乎专栏《放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较？](https://zhuanlan.zhihu.com/p/54743941)
- [张俊林知乎专栏《深度学习中的注意力模型（2017版）》](https://zhuanlan.zhihu.com/p/37601161)
- [Blog《The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)》](https://jalammar.github.io/illustrated-bert/)
- 机器学习研究会订阅号《图解2018年领先的两大NLP模型：BERT和ELMo》
- 大数据文摘《BERT大火却不懂Transformer？读这一篇就够了》





## 大神分享

- 微信《二十一世纪计算丨Yoshua Bengio：深度学习通往人类水平AI的挑战》
- 沈向洋《seven things I learned way achieving my career goal》https://www.linkedin.com/pulse/seven-things-i-learned-way-achieving-my-career-goal-harry-shum-1c/?from=timeline&isappinstalled=0
- 张俊林《推荐系统召回四模型之：全能的FM模型》https://zhuanlan.zhihu.com/p/58160982



## 专栏：

- gitchat：中文自然语言处理入门



## 微信公众号：

- 量子位、大数据文摘、机器之心、paperweekly、新智元、人工智能头条、微软研究院AI头条、AINLP

## 网站
+ [VReadTech:在网页上关注和浏览微信公众号](http://www.vreadtech.com)

## Comments

{% include comments.html %}
